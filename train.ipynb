{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T04:45:33.187912Z",
     "start_time": "2024-11-25T04:45:29.072152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "from sqlite3 import enable_callback_tracebacks\n",
    "\n",
    "import stanza\n",
    "from spacy.training.example import Alignment\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load a Chinese BERT tokenizer (you can use other models like RoBERTa or ERNIE)\n",
    "ch_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "class SentencePair:\n",
    "    def __init__(self, en, zh):\n",
    "        self.en = en\n",
    "        self.zh = zh\n",
    "\n",
    "# Initialize Stanza for Chinese word segmentation\n",
    "stanza.download('zh')  # Ensure the Chinese model is downloaded\n",
    "nlp = stanza.Pipeline('zh', processors='tokenize')\n",
    "\n",
    "rows = []\n",
    "def load_parallel_sentences(file_path):\n",
    "    sentence_pairs = []\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        # Loop through each row in the CSV file\n",
    "        for row in reader:\n",
    "            if len(row) < 7:\n",
    "                continue\n",
    "            english_content = row[5]  # Adjust based on the correct column index\n",
    "            chinese_content = row[6]  # Adjust based on the correct column index\n",
    "\n",
    "            # Split the content into sentences based on '@' delimiters\n",
    "            english_sentences = english_content.split('@')\n",
    "            chinese_sentences = chinese_content.split('@')\n",
    "            \n",
    "            for eng_sent, chi_sent in zip(english_sentences, chinese_sentences):\n",
    "                # Process the Chinese sentence with Stanza\n",
    "                doc = nlp(chi_sent)  # Apply the Stanza pipeline\n",
    "                ch_tokens = [word.text for sentence in doc.sentences for word in sentence.words]\n",
    "                            \n",
    "                # Join the words with spaces\n",
    "                ch_sentence = \" \".join(ch_tokens)\n",
    "                \n",
    "                sentence_pairs.append(SentencePair(eng_sent.strip(), ch_sentence.strip()))  \n",
    "            \n",
    "    \n",
    "    return sentence_pairs\n"
   ],
   "id": "6a590c10f3d9f126",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 13.6MB/s]                    \n",
      "2024-11-24 20:45:29 INFO: Downloaded file to /Users/vnnsnnt/stanza_resources/resources.json\n",
      "2024-11-24 20:45:29 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2024-11-24 20:45:29 INFO: Downloading default packages for language: zh-hans (Simplified_Chinese) ...\n",
      "2024-11-24 20:45:30 INFO: File exists: /Users/vnnsnnt/stanza_resources/zh-hans/default.zip\n",
      "2024-11-24 20:45:33 INFO: Finished downloading models and saved to /Users/vnnsnnt/stanza_resources\n",
      "2024-11-24 20:45:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 18.1MB/s]                    \n",
      "2024-11-24 20:45:33 INFO: Downloaded file to /Users/vnnsnnt/stanza_resources/resources.json\n",
      "2024-11-24 20:45:33 INFO: \"zh\" is an alias for \"zh-hans\"\n",
      "2024-11-24 20:45:33 INFO: Loading these models for language: zh-hans (Simplified_Chinese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsdsimp |\n",
      "=======================\n",
      "\n",
      "2024-11-24 20:45:33 INFO: Using device: cpu\n",
      "2024-11-24 20:45:33 INFO: Loading: tokenize\n",
      "2024-11-24 20:45:33 INFO: Done loading processors!\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:05:56.163251Z",
     "start_time": "2024-11-25T04:45:53.428886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "all_pairs = []\n",
    "directory_path = 'FTIE'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    \n",
    "    # Check if the path is a file and ends with .csv\n",
    "    if os.path.isfile(file_path) and filename.endswith('.csv'):\n",
    "        # Load pairs from the current file and extend the all_pairs list\n",
    "        file_pairs = load_parallel_sentences(file_path)\n",
    "        all_pairs.extend(file_pairs)\n"
   ],
   "id": "3c4070fcdeae1f5a",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:08:13.397298Z",
     "start_time": "2024-11-25T05:08:13.395256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(all_pairs[40].en)\n",
    "print(all_pairs[40].zh)"
   ],
   "id": "97f9a439051260c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the dawn of time, technology has constantly outpaced the law – but never quite as fast as in the digital age. Some of the most profitable and popular places on the internet today – from MySpace, to YouTube and beyond – exist in legal limbo. Every day, MySpacers and YouTubers commit millions of arguably unlawful acts: for when they are not posting riveting cellphone footage of the baby or the cat or the milk train passing, they are lip-syncing to the copyrighted songs of hot young starlets, or posting top-selling albums for free. Much of what the <em><i>digerati</i></em> do online is probably illegal: since the dawn of internet time, it was ever thus.\n",
      "自古 以来 ， 科技 的 发展 速度 一直 快 于 法律 ， 但 从来 没有 像 数码 时代 这样 差距 悬殊 。 如今 ， 互联 网上 赢利 最高 、 人气 最旺 的 一些 场所 — — 从 My Space 到 You Tube 到 其它 各色 网站 ， 都 生存 在 法律 的 空白 地带 。 MySpace 和 You Tube 用户 每天 的 “ 非法 行为 ” ， 可以 说 数 以 百万 计 ： 除 了 在 网上 发布 用 手机 拍摄 的 有关 婴儿 、 猫咪 或 送奶 卡车 的 视频 之外 ， 他们 还 经常 对 口型 假唱 当红 新 星 们 拥有 版权 的 歌曲 ， 或是 免费 发布 一些 畅销 专辑 。 这些 数码 玩家 的 许多 网络 行为 ， 很 可能 是 非法 的 ， 但 自 互联 网 出现 以来 ， 这 种 行为 就 一直 存在 。\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T02:37:55.817861Z",
     "start_time": "2024-11-24T02:26:11.423047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
    "\n",
    "# Load mBART model and tokenizer\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the source and target languages\n",
    "tokenizer.src_lang = \"zh_CN\"  # Use 'zh_CN' for Simplified Chinese\n",
    "tokenizer.tgt_lang = \"en_XX\"  # 'en_XX' for English\n",
    "\n",
    "# Sample Chinese sentence\n",
    "with open(\"unmodified_zh-en-translated_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    print(\"Translating\", len(all_pairs), \"sentences\")\n",
    "    for index, pair in enumerate(all_pairs):\n",
    "        chinese_sentence = pair.zh  # source\n",
    "        english_sentence = pair.en  # target\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(chinese_sentence, return_tensors=\"pt\")\n",
    "        # Generate translation\n",
    "        translated_tokens = model.generate(**inputs)\n",
    "        # Decode the translated tokens\n",
    "        translated_sentence = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Save the result in the text file\n",
    "        f.write(f\"{chinese_sentence}; {english_sentence}; {translated_sentence}\\n\")\n",
    "        \n",
    "        if index % 100 == 0: \n",
    "            print(\"Done with\", index, \"/\", len(all_pairs))"
   ],
   "id": "12b082515fe9f067",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'MBartTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating 255860 sentences\n",
      "Done with 0 / 255860\n",
      "Done with 100 / 255860\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(chinese_sentence, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Generate translation\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m translated_tokens \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Decode the translated tokens\u001B[39;00m\n\u001B[1;32m     24\u001B[0m translated_sentence \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(translated_tokens[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/generation/utils.py:2246\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2238\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2239\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2240\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2241\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2242\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2243\u001B[0m     )\n\u001B[1;32m   2245\u001B[0m     \u001B[38;5;66;03m# 13. run beam sample\u001B[39;00m\n\u001B[0;32m-> 2246\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_beam_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2247\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeam_scorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2252\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2254\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2256\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGROUP_BEAM_SEARCH:\n\u001B[1;32m   2257\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   2258\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   2259\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   2260\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2266\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   2267\u001B[0m     )\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/generation/utils.py:3455\u001B[0m, in \u001B[0;36mGenerationMixin._beam_search\u001B[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   3452\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m stack_model_outputs(outputs_per_sub_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget_text_config())\n\u001B[1;32m   3454\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Unchanged original behavior\u001B[39;00m\n\u001B[0;32m-> 3455\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3457\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3458\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3459\u001B[0m     outputs,\n\u001B[1;32m   3460\u001B[0m     model_kwargs,\n\u001B[1;32m   3461\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3462\u001B[0m )\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:1610\u001B[0m, in \u001B[0;36mMBartForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1607\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1608\u001B[0m         decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id)\n\u001B[0;32m-> 1610\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1611\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1615\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1618\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1620\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1622\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1623\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1624\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1626\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1627\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_logits_bias\n\u001B[1;32m   1629\u001B[0m masked_lm_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:1496\u001B[0m, in \u001B[0;36mMBartModel.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1489\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[1;32m   1490\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1491\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1492\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1493\u001B[0m     )\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1496\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1497\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1498\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1499\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1500\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_outputs \u001B[38;5;241m+\u001B[39m encoder_outputs\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:1355\u001B[0m, in \u001B[0;36mMBartDecoder.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1342\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1343\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1344\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1352\u001B[0m         use_cache,\n\u001B[1;32m   1353\u001B[0m     )\n\u001B[1;32m   1354\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1355\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1357\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1362\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   1363\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1364\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1365\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1366\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1367\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1368\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:684\u001B[0m, in \u001B[0;36mMBartDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001B[39;00m\n\u001B[1;32m    683\u001B[0m cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 684\u001B[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    692\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(hidden_states, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    693\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:516\u001B[0m, in \u001B[0;36mMBartSdpaAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001B[39;00m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001B[39;00m\n\u001B[1;32m    514\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mreshape(bsz, tgt_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_dim)\n\u001B[0;32m--> 516\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m attn_output, \u001B[38;5;28;01mNone\u001B[39;00m, past_key_value\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T10:14:37.030055Z",
     "start_time": "2024-11-24T10:14:20.229357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'alignments.txt'\n",
    "\n",
    "# Initialize a list to store (en, zh) pairs\n",
    "alignment_pairs = []\n",
    "\n",
    "class AlignmentPair: \n",
    "    def __init__(self, en, zh):\n",
    "        self.en = en\n",
    "        self.zh = zh\n",
    "        \n",
    "# Open and process the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "    \n",
    "        # Split the line into segments by spcae\n",
    "        segments = line.strip().split(' ')\n",
    "      \n",
    "        for segment in segments:\n",
    "            # Split the segment by '<sep>'\n",
    "            tokens = segment.split('<sep>')\n",
    "            clean_en = re.sub(r'[^\\w\\s]', '', tokens[0]).strip()\n",
    "            clean_zh = re.sub(r'[^\\w\\s]', '', tokens[1]).strip()\n",
    "            alignment_pairs.append(AlignmentPair(clean_en, clean_zh))\n",
    "        "
   ],
   "id": "978db8f9c02828a2",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T10:41:11.101681Z",
     "start_time": "2024-11-24T10:41:06.526640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "suitable_alignment_pairs = []\n",
    "english_pattern = re.compile(r'^[A-Za-z0-9\\s.,?!\\'\"-]+$')  # Matches English letters, digits, spaces, and common punctuation\n",
    "chinese_pattern = re.compile(r'^[\\u4e00-\\u9fff]+$')         # Matches Chinese characters (CJK Unified Ideographs)\n",
    "\n",
    "for pair in alignment_pairs:\n",
    "    if pair.en == pair.zh:\n",
    "        continue\n",
    "    if pair.en == \"\":\n",
    "        continue\n",
    "    if pair.zh == \"\":\n",
    "        continue\n",
    "\n",
    "    # Check if pair.en is all English and pair.zh is all Chinese\n",
    "    if not english_pattern.match(pair.en.strip()):  # Ensure `en` is all English\n",
    "        continue\n",
    "    if not chinese_pattern.match(pair.zh.strip()):  # Ensure `zh` is all Chinese\n",
    "        continue\n",
    "\n",
    "    suitable_alignment_pairs.append(pair)"
   ],
   "id": "763a7d4e2d11641d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T10:45:10.548667Z",
     "start_time": "2024-11-24T10:45:10.545583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for suitable_alignment_pair in suitable_alignment_pairs[0:100]:\n",
    "    print(suitable_alignment_pair.en, suitable_alignment_pair.zh)"
   ],
   "id": "bd03e0fdf8504f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commodity 商品\n",
      "trader 交易商\n",
      "fighting 应对\n",
      "allegations 指控\n",
      "aggressive 出格\n",
      "accounting 会计\n",
      "accounting 操作\n",
      "has 已\n",
      "raised 出售\n",
      "750m 亿美元\n",
      "the 的\n",
      "sale 出售\n",
      "its 其\n",
      "stake 股份\n",
      "in 在\n",
      "agricultural 农业\n",
      "joint 合资企业\n",
      "venture 合资企业\n",
      "with 与\n",
      "Chinas 中国\n",
      "statebacked 国有\n",
      "statebacked 合资企业\n",
      "grain 粮食\n",
      "trader 贸易商\n",
      "The 的\n",
      "Hong 香港\n",
      "Kongbased 香港\n",
      "Kongbased 位于\n",
      "company 集团\n",
      "has 近来\n",
      "scrambling 忙于\n",
      "to 忙于\n",
      "raise 筹集资金\n",
      "cash 筹集资金\n",
      "to 以免\n",
      "avoid 以免\n",
      "losing 失去\n",
      "its 其\n",
      "investment 投资\n",
      "grade 级\n",
      "credit 信用\n",
      "rating 评级\n",
      "which 这种\n",
      "crucial 至关重要\n",
      "to 对于\n",
      "the 的\n",
      "profitability 盈利\n",
      "profitability 能力\n",
      "of 对于\n",
      "its 其\n",
      "core 核心\n",
      "business 业务\n",
      "moving 从事\n",
      "moving 贸易\n",
      "millions 大量\n",
      "tonnes 大量\n",
      "of 的\n",
      "raw 原材料\n",
      "materials 原材料\n",
      "around 世界各地\n",
      "world 世界各地\n",
      "Noble 来宝\n",
      "which 的\n",
      "listed 上市\n",
      "in 在\n",
      "Singapore 新加坡\n",
      "until 最迟在\n",
      "early 明年初\n",
      "next 明年初\n",
      "year 明年初\n",
      "by 面对\n",
      "rating 评级\n",
      "agencies 机构\n",
      "and 和\n",
      "raise 筹集\n",
      "at 至少\n",
      "least 至少\n",
      "500m 亿美元\n",
      "or 否则\n",
      "being 被\n",
      "cut 下调\n",
      "to 至\n",
      "junk 垃圾\n",
      "status 级\n",
      "To 在\n",
      "his 的\n",
      "many 诸多\n",
      "achievements 成就\n",
      "film 电影\n",
      "producer 制片人\n",
      "philanthropist 慈善家\n",
      "serial 连环\n",
      "sex 性\n",
      "offender 侵者\n",
      "can 可以\n",
      "add 加上\n",
      "failed 失败\n",
      "lobbyist 游说\n",
      "lobbyist 者\n",
      "for 获得\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:23:54.670070Z",
     "start_time": "2024-11-25T05:22:18.731060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the set of stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words.update(\n",
    "    {'cent', 'href=', 'http', 'says', 'told', 'year', 'ago', 'yesterday', 'since', 'last', 'past', 'next',\n",
    "     'said', 'almost', 'within', 'would', 'nearly', 'years', 'months', 'according', 'compared', 'go', 'also', \n",
    "     \"n't\"})  # Using update to add multiple elements\n",
    "\n",
    "punctuation_set = set(punctuation)\n",
    "punctuation_set.update({\"’\", \"’\", '”', \"''\", \"“\", \"'s\", '--', 'b', '/b', '/strong', '–', '—'})  # Adding custom punctuation symbols\n",
    "\n",
    "def extract_ngram_counts(sentence_pairs, n=2):\n",
    "    ngram_counts = Counter()\n",
    "\n",
    "    # Iterate through each sentence pair\n",
    "    for pair in sentence_pairs:\n",
    "        # Tokenize the English sentence (p.en)\n",
    "        tokens = nltk.word_tokenize(pair.en)\n",
    "\n",
    "        # Filter out stopwords, punctuation, and numbers\n",
    "        filtered_tokens = [token.lower() for token in tokens \n",
    "                           if token.lower() not in stop_words \n",
    "                           and token not in punctuation_set \n",
    "                           and not token.isdigit()]  # Exclude numeric tokens\n",
    "\n",
    "        # Generate n-grams for the filtered tokens\n",
    "        ngram_list = ngrams(filtered_tokens, n)\n",
    "\n",
    "        # Count the frequency of each n-gram\n",
    "        ngram_counts.update(ngram_list)\n",
    "\n",
    "    return ngram_counts\n",
    "\n",
    "# extract bigrams, trigrams, and 4-grams\n",
    "bigram = extract_ngram_counts(all_pairs, 2)     # 10k\n",
    "trigram = extract_ngram_counts(all_pairs, 3)    # 5k\n",
    "quad_gram = extract_ngram_counts(all_pairs, 4)  # 3k\n",
    "# pent_gram = extract_ngram_counts(all_pairs, 5)  # 1k"
   ],
   "id": "6ab5831261a8f141",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vnnsnnt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vnnsnnt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:26:47.752572Z",
     "start_time": "2024-11-25T05:26:46.100402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bigrams_to_consider = bigram.most_common()[0:5000]\n",
    "trigrams_to_consider = trigram.most_common()[:1000]\n",
    "quad_grams_to_consider = quad_gram.most_common()[:3000]"
   ],
   "id": "a261b362eeb8967c",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:11:05.435179Z",
     "start_time": "2024-11-25T05:11:05.432867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multi_word_term = '_'.join(quad_grams_to_consider[0][0])\n",
    "print(multi_word_term)"
   ],
   "id": "c7a4bed0d487ee6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per_gross_domestic_product\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:26:59.857008Z",
     "start_time": "2024-11-25T05:26:59.489012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a set for multi-word terms\n",
    "multi_grams_to_consider = set()\n",
    "\n",
    "# Add multi-word terms from quad_grams_to_consider\n",
    "for quad_gram in quad_grams_to_consider:\n",
    "    multi_word_term = '_'.join(quad_gram[0])\n",
    "    multi_grams_to_consider.add(multi_word_term)\n",
    "\n",
    "# Add multi-word terms from trigrams_to_consider\n",
    "for trigram in trigrams_to_consider:\n",
    "    multi_word_term = '_'.join(trigram[0])\n",
    "    multi_grams_to_consider.add(multi_word_term)\n",
    "\n",
    "# Add multi-word terms from bigrams_to_consider\n",
    "for bigram in bigrams_to_consider:\n",
    "    multi_word_term = '_'.join(bigram[0])\n",
    "    multi_grams_to_consider.add(multi_word_term)"
   ],
   "id": "893016911b54c569",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:28:25.218225Z",
     "start_time": "2024-11-25T05:28:25.215871Z"
    }
   },
   "cell_type": "code",
   "source": "len(multi_grams_to_consider)",
   "id": "b83f253338edbf6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:28:47.247072Z",
     "start_time": "2024-11-25T05:28:47.242772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_with_multi_word_terms(sentence, multi_grams_to_consider):\n",
    "    # Tokenize the sentence into words\n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    # Prepare a list to hold the modified sentence\n",
    "    modified_sentence = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        found = False\n",
    "        \n",
    "        # Check for quadgrams (4-word sequences)\n",
    "        for length in range(4, 1, -1):  # Check for quadgram to bigram\n",
    "            if i + length <= len(words):\n",
    "                multi_word_candidate = '_'.join(words[i:i+length]).lower()\n",
    "                if multi_word_candidate in multi_grams_to_consider:\n",
    "                    # If a match is found, replace the words with the multi-word term\n",
    "                    modified_sentence.append(multi_word_candidate)\n",
    "                    i += length\n",
    "                    found = True\n",
    "                    break\n",
    "        \n",
    "        if not found:\n",
    "            # If no match is found, just add the word as is\n",
    "            modified_sentence.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Return the modified sentence as a string\n",
    "    return ' '.join(modified_sentence)"
   ],
   "id": "be873df81ded4911",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T05:29:00.533023Z",
     "start_time": "2024-11-25T05:28:50.365260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming all_pairs contains your sentence pairs and you have the function replace_with_multi_word_terms defined\n",
    "with open(\"zhen.src-tgt\", \"w\") as f:\n",
    "    for pair in all_pairs:\n",
    "        # Modify the sentence using your function\n",
    "        modified_sentence = replace_with_multi_word_terms(pair.en, multi_grams_to_consider)\n",
    "        \n",
    "        # Save the modified sentence along with the corresponding Chinese sentence\n",
    "        f.write(f\"{modified_sentence} ||| {pair.zh}\\n\")\n",
    "\n",
    "print(\"Modified sentences saved to 'modified_sentences.txt'\")"
   ],
   "id": "d9e72d32a3b4ecb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified sentences saved to 'modified_sentences.txt'\n"
     ]
    }
   ],
   "execution_count": 209
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TermAlignment:\n",
    "    def __init__(self, en, zh):\n",
    "        self.en = en\n",
    "        self.zh = zh\n",
    "        \n",
    "# Function to clean text to retain only alphabets\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z_]', '', text)\n",
    "\n",
    "multiword_alignments = []\n",
    "# Process the alignments.txt file\n",
    "with open('alignments.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        alignment_pairs = line.strip().split(' ')\n",
    "        for index, pair in enumerate(alignment_pairs):\n",
    "            en_entry, zh_entry = pair.split('<sep>')[0], pair.split('<sep>')[1]\n",
    "            if en_entry not in multi_grams_to_consider: continue\n",
    "            # Clean the English entry\n",
    "            cleaned_en_entry = clean_text(en_entry)\n",
    "\n",
    "            # Append only if conditions are met\n",
    "            if cleaned_en_entry:\n",
    "                if multiword_alignments and multiword_alignments[len(multiword_alignments)-1].en == cleaned_en_entry:\n",
    "                    if zh_entry not in multiword_alignments[len(multiword_alignments)-1].zh:\n",
    "                        multiword_alignments[len(multiword_alignments)-1].zh += zh_entry\n",
    "                else:\n",
    "                    multiword_alignments.append(TermAlignment(cleaned_en_entry, zh_entry))"
   ],
   "id": "51ffd05fe4c3cef3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T13:19:55.145583Z",
     "start_time": "2024-11-25T13:19:55.053451Z"
    }
   },
   "cell_type": "code",
   "source": "unique_alignments = set(TermAlignment(alignment.en, alignment.zh) for alignment in multiword_alignments)",
   "id": "763269eebce97485",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T13:27:11.198455Z",
     "start_time": "2024-11-25T13:27:11.011022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Step 1: Count frequencies of `zh` entries for each `en`\n",
    "alignment_freq = defaultdict(Counter)\n",
    "\n",
    "for alignment in unique_alignments:\n",
    "    alignment_freq[alignment.en][alignment.zh] += 1\n",
    "\n",
    "# Step 2: Select the most frequent `zh` entry for each `en`\n",
    "simplified_alignments = []\n",
    "for en, zh_counter in alignment_freq.items():\n",
    "    most_frequent_zh = zh_counter.most_common(1)[0][0]  # Get the most frequent `zh`\n",
    "    simplified_alignments.append(TermAlignment(en, most_frequent_zh))\n",
    "\n",
    "# Step 3: Sort alphabetically by `en`\n",
    "sorted_simplified_alignments = sorted(simplified_alignments, key=lambda alignment: alignment.en)\n",
    "\n",
    "# Step 4: Write to file\n",
    "with open('simplified-alignments.txt', 'w') as file:\n",
    "    for alignment in sorted_simplified_alignments:\n",
    "        file.write(f\"{alignment.en} {alignment.zh}\\n\")"
   ],
   "id": "9178aa39c06c1f93",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b457f0aad00b994"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
