{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:04.454311Z",
     "start_time": "2024-12-11T01:44:04.452003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
    "import sacrebleu\n",
    "import pandas as pd"
   ],
   "id": "b3a95fa809a55078",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:09.341205Z",
     "start_time": "2024-12-11T01:44:04.572423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pretrained mBART model and tokenizer\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)"
   ],
   "id": "e87ac29b29c83553",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'MBartTokenizer'.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:09.346792Z",
     "start_time": "2024-12-11T01:44:09.344488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set source and target languages\n",
    "tokenizer.src_lang = \"zh_CN\"\n",
    "tokenizer.tgt_lang = \"en_XX\""
   ],
   "id": "a31018991223dd58",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:09.360141Z",
     "start_time": "2024-12-11T01:44:09.353055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "4770147c383cf1bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x MBartEncoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x MBartDecoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:10.612665Z",
     "start_time": "2024-12-11T01:44:09.366627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load parallel sentences (zh-en) and anchor word dictionary\n",
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "parallel_sentences = list(zip(train_df['zh'], train_df['en']))[0:1000]"
   ],
   "id": "d54ddc24739a9b34",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:10.622514Z",
     "start_time": "2024-12-11T01:44:10.618420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load anchor word dictionary\n",
    "anchor_word_dict = {}\n",
    "with open(\"final_anchors.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        zh_anchor, en_anchor = line.strip().split()\n",
    "        anchor_word_dict['<'+zh_anchor+'>'] = '<' + en_anchor + '>'"
   ],
   "id": "1829c95c76f0f584",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:15.580980Z",
     "start_time": "2024-12-11T01:44:10.628245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "tokens_to_be_added = []\n",
    "with open('tokens_to_be_added.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        tokens_to_be_added.append(line.strip())\n",
    "        \n",
    "# Add custom tokens and resize model embeddings\n",
    "tokenizer.add_tokens(tokens_to_be_added)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ],
   "id": "883fe9e774e8a0f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBartScaledWordEmbedding(255669, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:15.593065Z",
     "start_time": "2024-12-11T01:44:15.591254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reward weights\n",
    "lambda_bleu = 0.7\n",
    "lambda_anchor = 0.3"
   ],
   "id": "703a699b92415218",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:15.604146Z",
     "start_time": "2024-12-11T01:44:15.601802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_reward(generated, reference, input_sentence):\n",
    "    # BLEU reward (Scaled up for more impact)\n",
    "    bleu_score = sacrebleu.sentence_bleu(generated, [reference]).score / 100.0\n",
    "    bleu_reward = bleu_score * lambda_bleu  # Larger weight for BLEU\n",
    "\n",
    "    # Anchor word reward (Count all matches)\n",
    "    anchor_reward = sum(1.0 for zh_anchor, en_anchor in anchor_word_dict.items() if zh_anchor in input_sentence and en_anchor in generated)\n",
    "\n",
    "    # Optionally normalize or not (for now, no normalization to make it more impactful)\n",
    "    # anchor_reward = anchor_reward / max(len(anchor_word_dict), 1)  # If you want normalization\n",
    "\n",
    "    # Weighted total reward\n",
    "    total_reward = bleu_reward + lambda_anchor * anchor_reward\n",
    "    print(total_reward, bleu_reward, anchor_reward)\n",
    "    return total_reward"
   ],
   "id": "68089677245d4685",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:44:15.618139Z",
     "start_time": "2024-12-11T01:44:15.614164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RL loop setup\n",
    "def fine_tune_with_rl(model, tokenizer, parallel_sentences, num_epochs=1, log_interval=100):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)  # Increase the learning rate\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct_translations = 0\n",
    "        total_examples = 0\n",
    "\n",
    "        for idx, (zh_sentence, en_reference) in enumerate(parallel_sentences):\n",
    "            # Tokenize input sentence\n",
    "            inputs = tokenizer(zh_sentence, return_tensors=\"pt\", truncation=True, max_length=256).to(device)\n",
    "\n",
    "            # Generate translation with forced BOS token\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
    "            )\n",
    "            generated_tokens = outputs[0]\n",
    "            generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "            # Compute reward\n",
    "            reward = compute_reward(generated_text, en_reference, zh_sentence)\n",
    "\n",
    "            # Get model logits (without softmax applied) to calculate log probabilities\n",
    "            model_outputs = model(**inputs, labels=generated_tokens.unsqueeze(0))\n",
    "            logits = model_outputs.logits  # Shape: (batch_size, seq_len, vocab_size)\n",
    "            \n",
    "            # Get the log probabilities of the generated tokens\n",
    "            log_probs = torch.log_softmax(logits, dim=-1)  # Apply softmax to logits and then take the log\n",
    "            \n",
    "            # Get the log probability of the generated tokens\n",
    "            log_prob = 0\n",
    "            for t, token in enumerate(generated_tokens):\n",
    "                log_prob += log_probs[0, t, token]  # Sum log probabilities of the generated tokens\n",
    "\n",
    "            # Compute policy loss (-reward * log_prob)\n",
    "            policy_loss = -reward * log_prob\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += policy_loss.item()\n",
    "            total_examples += 1\n",
    "            if reward > 0.8:  # Example threshold for correct translations\n",
    "                correct_translations += 1\n",
    "\n",
    "            # Logging progress\n",
    "            if (idx + 1) % log_interval == 0:\n",
    "                accuracy = correct_translations / total_examples\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Step {idx + 1}/{len(parallel_sentences)}, Loss: {total_loss / total_examples:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # End of epoch log\n",
    "        accuracy = correct_translations / total_examples\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} completed. Average Loss: {total_loss / total_examples:.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "id": "1424e842861787e0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T01:46:38.261112Z",
     "start_time": "2024-12-11T01:44:15.626776Z"
    }
   },
   "cell_type": "code",
   "source": "fine_tune_with_rl(model, tokenizer, parallel_sentences, num_epochs=3, log_interval=5)",
   "id": "a07088138b26f721",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06186229357998088 0.06186229357998088 0\n",
      "0.12103485505975332 0.12103485505975332 0\n",
      "0.07972513809448918 0.07972513809448918 0\n",
      "0.04300622298506018 0.04300622298506018 0\n",
      "0.02363345370051766 0.02363345370051766 0\n",
      "Epoch 1/3, Step 5/1000, Loss: 2.1475, Accuracy: 0.0000\n",
      "0.06405407836463438 0.06405407836463438 0\n",
      "0.036273302413397705 0.036273302413397705 0\n",
      "0.02074201918486772 0.02074201918486772 0\n",
      "0.011853781513057045 0.011853781513057045 0\n",
      "0.009221176051421096 0.009221176051421096 0\n",
      "Epoch 1/3, Step 10/1000, Loss: 1.3629, Accuracy: 0.0000\n",
      "0.001288341869479308 0.001288341869479308 0\n",
      "0.003970076429902533 0.003970076429902533 0\n",
      "0.00011022187891041029 0.00011022187891041029 0\n",
      "3.230361633773976e-05 3.230361633773976e-05 0\n",
      "7.873183048546209e-09 7.873183048546209e-09 0\n",
      "Epoch 1/3, Step 15/1000, Loss: 0.9128, Accuracy: 0.0000\n",
      "0.0003055892584092149 0.0003055892584092149 0\n",
      "0.00060731716403617 0.00060731716403617 0\n",
      "0.0007615969223167628 0.0007615969223167628 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 20/1000, Loss: 0.6856, Accuracy: 0.0000\n",
      "7.214037678534951e-10 7.214037678534951e-10 0\n",
      "0.0 0.0 0\n",
      "1.1271099773927855e-05 1.1271099773927855e-05 0\n",
      "6.076043253071946e-07 6.076043253071946e-07 0\n",
      "8.223030346124015e-08 8.223030346124015e-08 0\n",
      "Epoch 1/3, Step 25/1000, Loss: 0.5485, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "3.3174072113909595e-05 3.3174072113909595e-05 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 30/1000, Loss: 0.4571, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 35/1000, Loss: 0.3918, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 40/1000, Loss: 0.3428, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "1.630610150786189e-15 1.630610150786189e-15 0\n",
      "Epoch 1/3, Step 45/1000, Loss: 0.3047, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "2.4149088952863408e-12 2.4149088952863408e-12 0\n",
      "9.742437820202425e-10 9.742437820202425e-10 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 50/1000, Loss: 0.2742, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 55/1000, Loss: 0.2493, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 60/1000, Loss: 0.2285, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 65/1000, Loss: 0.2110, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "Epoch 1/3, Step 70/1000, Loss: 0.1959, Accuracy: 0.0000\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfine_tune_with_rl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_sentences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 46\u001B[0m, in \u001B[0;36mfine_tune_with_rl\u001B[0;34m(model, tokenizer, parallel_sentences, num_epochs, log_interval)\u001B[0m\n\u001B[1;32m     44\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     45\u001B[0m policy_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 46\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m policy_loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     49\u001B[0m total_examples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    485\u001B[0m             )\n\u001B[0;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/adamw.py:220\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    207\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m cast(Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m], group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    209\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    210\u001B[0m         group,\n\u001B[1;32m    211\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    217\u001B[0m         state_steps,\n\u001B[1;32m    218\u001B[0m     )\n\u001B[0;32m--> 220\u001B[0m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/adamw.py:782\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    780\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 782\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Project-NLP/venv/lib/python3.9/site-packages/torch/optim/adamw.py:427\u001B[0m, in \u001B[0;36m_single_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[1;32m    425\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    426\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 427\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    429\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36acf76dbf2abfc2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
